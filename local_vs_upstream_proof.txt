🔬 LOCAL FORK vs UPSTREAM BASELINE
======================================================================
📚 Testing with 27 real markdown files


🔍 Query: 'How to configure GPU embeddings for semantic search?...'
----------------------------------------------------------------------

  🚀 Local GPU (Gemma-768D)
     Quality: 0.443 avg similarity
     Speed: 0.25s
     Best: GPU_EMBEDDING_TEST_CRITERIA.md... (0.520)

  🐌 Upstream Baseline (MiniLM-384D CPU)
     Quality: 0.190 avg similarity
     Speed: 2.97s
     Best: docs/unified_search_llm_prompt.md... (0.541)

🔍 Query: 'Multi-agent coordination and orchestration patterns...'
----------------------------------------------------------------------

  🚀 Local GPU (Gemma-768D)
     Quality: 0.417 avg similarity
     Speed: 0.14s
     Best: CLAUDE.md... (0.498)

  🐌 Upstream Baseline (MiniLM-384D CPU)
     Quality: 0.201 avg similarity
     Speed: 1.94s
     Best: CLAUDE.md... (0.549)

🔍 Query: 'Knowledge graph implementation with vector databases...'
----------------------------------------------------------------------

  🚀 Local GPU (Gemma-768D)
     Quality: 0.387 avg similarity
     Speed: 0.14s
     Best: GPU_EMBEDDING_TEST_CRITERIA.md... (0.465)

  🐌 Upstream Baseline (MiniLM-384D CPU)
     Quality: 0.178 avg similarity
     Speed: 1.79s
     Best: docs/LANCEDB.md... (0.484)

======================================================================
📊 SUMMARY: LOCAL FORK SUPERIORITY
======================================================================

🏆 Local Fork (Gemma-768D GPU):
   Quality: 0.416
   Speed: 0.18s
   Dimensions: 768D (2x richer)

📦 Upstream Baseline (MiniLM-384D CPU):
   Quality: 0.190
   Speed: 2.23s
   Dimensions: 384D

🎯 PROVEN ADVANTAGE:
   Quality: +119.1% better semantic understanding
   Speed: 12.7x faster
   Cost: FREE (local GPU vs local CPU)

💾 Saved to local_vs_upstream_results.json
